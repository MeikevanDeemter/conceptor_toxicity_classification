{
  "summary": {
    "description": "Average metrics across all seeds for each model and approach",
    "total_models": 3,
    "approaches": [
      "conceptor_based",
      "mean_activation_based"
    ],
    "metrics_calculated": [
      "accuracy",
      "precision",
      "recall",
      "f1_score",
      "TP",
      "FP",
      "TN",
      "FN"
    ]
  },
  "models": {
    "EleutherAI-gpt-neo-125M": {
      "conceptor_based": {
        "mean_accuracy": 0.7569999999999999,
        "std_accuracy": 0.012561846997953775,
        "mean_precision": 0.796395750999795,
        "std_precision": 0.01351202530864374,
        "mean_recall": 0.6908000000000001,
        "std_recall": 0.025174590364095275,
        "mean_f1_score": 0.7395762160730882,
        "std_f1_score": 0.01610520755530295,
        "mean_TP": 172.7,
        "std_TP": 6.293647591023825,
        "mean_FP": 44.2,
        "std_FP": 3.815756805667782,
        "mean_TN": 205.8,
        "std_TN": 3.815756805667782,
        "mean_FN": 77.3,
        "std_FN": 6.293647591023825,
        "n_seeds": 10,
        "seeds_processed": [
          "seed_42",
          "seed_7",
          "seed_12345",
          "seed_1337",
          "seed_2024",
          "seed_271828",
          "seed_31415",
          "seed_777",
          "seed_8675309",
          "seed_9001"
        ]
      },
      "mean_activation_based": {
        "mean_accuracy": 0.7485515030060121,
        "std_accuracy": 0.023459527363927427,
        "mean_precision": 0.748015662820334,
        "std_precision": 0.02425377052220793,
        "mean_recall": 0.7499036144578314,
        "std_recall": 0.02826580797909871,
        "mean_f1_score": 0.7487876637579726,
        "std_f1_score": 0.02382070213036208,
        "mean_TP": 187.4,
        "std_TP": 7.045565981523414,
        "mean_FP": 63.2,
        "std_FP": 6.954135460285484,
        "mean_TN": 186.8,
        "std_TN": 6.9541354602854835,
        "mean_FN": 62.5,
        "std_FN": 7.074602462329597,
        "n_seeds": 10,
        "seeds_processed": [
          "seed_42",
          "seed_7",
          "seed_12345",
          "seed_1337",
          "seed_2024",
          "seed_271828",
          "seed_31415",
          "seed_777",
          "seed_8675309",
          "seed_9001"
        ]
      }
    },
    "EleutherAI-gpt-neo-1.3B": {
      "conceptor_based": {
        "mean_accuracy": 0.7786,
        "std_accuracy": 0.022181974664127628,
        "mean_precision": 0.8026667289157704,
        "std_precision": 0.028330711517437015,
        "mean_recall": 0.7396,
        "std_recall": 0.02258849264559282,
        "mean_f1_score": 0.7696633453631099,
        "std_f1_score": 0.022432564870792676,
        "mean_TP": 184.9,
        "std_TP": 5.6471231613982,
        "mean_FP": 45.6,
        "std_FP": 7.391887445030532,
        "mean_TN": 204.4,
        "std_TN": 7.39188744503053,
        "mean_FN": 65.1,
        "std_FN": 5.6471231613982,
        "n_seeds": 10,
        "seeds_processed": [
          "seed_42",
          "seed_7",
          "seed_12345",
          "seed_1337",
          "seed_2024",
          "seed_271828",
          "seed_31415",
          "seed_777",
          "seed_8675309",
          "seed_9001"
        ]
      },
      "mean_activation_based": {
        "mean_accuracy": 0.7727999999999999,
        "std_accuracy": 0.0228595712995673,
        "mean_precision": 0.7962561693927797,
        "std_precision": 0.02228771356642858,
        "mean_recall": 0.7332,
        "std_recall": 0.0331324614238061,
        "mean_f1_score": 0.7631912397498248,
        "std_f1_score": 0.025923002313900954,
        "mean_TP": 183.3,
        "std_TP": 8.283115355951528,
        "mean_FP": 46.9,
        "std_FP": 5.52177507691141,
        "mean_TN": 203.1,
        "std_TN": 5.52177507691141,
        "mean_FN": 66.7,
        "std_FN": 8.283115355951528,
        "n_seeds": 10,
        "seeds_processed": [
          "seed_42",
          "seed_7",
          "seed_12345",
          "seed_1337",
          "seed_2024",
          "seed_271828",
          "seed_31415",
          "seed_777",
          "seed_8675309",
          "seed_9001"
        ]
      }
    },
    "EleutherAI-gpt-neo-2.7B": {
      "conceptor_based": {
        "mean_accuracy": 0.7814,
        "std_accuracy": 0.02371581750646601,
        "mean_precision": 0.8045018560907297,
        "std_precision": 0.030861640558504762,
        "mean_recall": 0.7444,
        "std_recall": 0.022800000000000018,
        "mean_f1_score": 0.7730886756413817,
        "std_f1_score": 0.023700669964386883,
        "mean_TP": 186.1,
        "std_TP": 5.7,
        "mean_FP": 45.4,
        "std_FP": 8.077128202523468,
        "mean_TN": 204.6,
        "std_TN": 8.07712820252347,
        "mean_FN": 63.9,
        "std_FN": 5.7,
        "n_seeds": 10,
        "seeds_processed": [
          "seed_42",
          "seed_7",
          "seed_12345",
          "seed_1337",
          "seed_2024",
          "seed_271828",
          "seed_31415",
          "seed_777",
          "seed_8675309",
          "seed_9001"
        ]
      },
      "mean_activation_based": {
        "mean_accuracy": 0.7806000000000001,
        "std_accuracy": 0.021799999999999996,
        "mean_precision": 0.7961879380450383,
        "std_precision": 0.025357595972760345,
        "mean_recall": 0.7548,
        "std_recall": 0.02446548589339687,
        "mean_f1_score": 0.7747777745403684,
        "std_f1_score": 0.02239029082264458,
        "mean_TP": 188.7,
        "std_TP": 6.116371473349211,
        "mean_FP": 48.4,
        "std_FP": 6.814690014960328,
        "mean_TN": 201.6,
        "std_TN": 6.814690014960329,
        "mean_FN": 61.3,
        "std_FN": 6.1163714733492105,
        "n_seeds": 10,
        "seeds_processed": [
          "seed_42",
          "seed_7",
          "seed_12345",
          "seed_1337",
          "seed_2024",
          "seed_271828",
          "seed_31415",
          "seed_777",
          "seed_8675309",
          "seed_9001"
        ]
      }
    }
  }
}