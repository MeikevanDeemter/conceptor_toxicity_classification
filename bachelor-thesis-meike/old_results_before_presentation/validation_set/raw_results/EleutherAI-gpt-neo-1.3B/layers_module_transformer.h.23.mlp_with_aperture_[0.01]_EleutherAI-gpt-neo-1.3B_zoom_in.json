{
  "model": "EleutherAI-gpt-neo-1.3B",
  "experiment": {
    "type": "layers",
    "module": "transformer.h.23.mlp"
  },
  "metrics": {
    "validation_scores": {
      "transformer.h.18.ln_1": 0.788,
      "transformer.h.18.attn": 0.784,
      "transformer.h.18.ln_2": 0.792,
      "transformer.h.18.mlp": 0.812,
      "transformer.h.19.ln_1": 0.792,
      "transformer.h.19.attn": 0.768,
      "transformer.h.19.ln_2": 0.804,
      "transformer.h.19.mlp": 0.8,
      "transformer.h.20.ln_1": 0.804,
      "transformer.h.20.attn": 0.772,
      "transformer.h.20.ln_2": 0.808,
      "transformer.h.20.mlp": 0.8,
      "transformer.h.21.ln_1": 0.804,
      "transformer.h.21.attn": 0.784,
      "transformer.h.21.ln_2": 0.808,
      "transformer.h.21.mlp": 0.788,
      "transformer.h.22.ln_1": 0.808,
      "transformer.h.22.attn": 0.792,
      "transformer.h.22.ln_2": 0.804,
      "transformer.h.22.mlp": 0.812,
      "transformer.h.23.ln_1": 0.804,
      "transformer.h.23.attn": 0.796,
      "transformer.h.23.ln_2": 0.828,
      "transformer.h.23.mlp": 0.764
    },
    "training_scores": {},
    "test_scores": {}
  },
  "parameters": {
    "aperture": [
      0.01
    ],
    "n_examples": [
      250
    ]
  }
}