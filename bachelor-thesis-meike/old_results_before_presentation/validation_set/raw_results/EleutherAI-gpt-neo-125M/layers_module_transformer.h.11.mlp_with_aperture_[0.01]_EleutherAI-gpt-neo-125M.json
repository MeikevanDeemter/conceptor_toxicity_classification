{
  "model": "EleutherAI-gpt-neo-125M",
  "experiment": {
    "type": "layers",
    "module": "transformer.h.11.mlp"
  },
  "metrics": {
    "validation_scores": {
      "transformer.h.1.ln_1": 0.66,
      "transformer.h.1.attn": 0.652,
      "transformer.h.1.ln_2": 0.56,
      "transformer.h.1.mlp": 0.656,
      "transformer.h.2.ln_1": 0.568,
      "transformer.h.2.attn": 0.524,
      "transformer.h.2.ln_2": 0.624,
      "transformer.h.2.mlp": 0.684,
      "transformer.h.3.ln_1": 0.632,
      "transformer.h.3.attn": 0.536,
      "transformer.h.3.ln_2": 0.632,
      "transformer.h.3.mlp": 0.7,
      "transformer.h.4.ln_1": 0.64,
      "transformer.h.4.attn": 0.64,
      "transformer.h.4.ln_2": 0.64,
      "transformer.h.4.mlp": 0.724,
      "transformer.h.5.ln_1": 0.652,
      "transformer.h.5.attn": 0.616,
      "transformer.h.5.ln_2": 0.672,
      "transformer.h.5.mlp": 0.724,
      "transformer.h.6.ln_1": 0.668,
      "transformer.h.6.attn": 0.6827309236947792,
      "transformer.h.6.ln_2": 0.684,
      "transformer.h.6.mlp": 0.692,
      "transformer.h.7.ln_1": 0.676,
      "transformer.h.7.attn": 0.668,
      "transformer.h.7.ln_2": 0.7,
      "transformer.h.7.mlp": 0.724,
      "transformer.h.8.ln_1": 0.684,
      "transformer.h.8.attn": 0.716,
      "transformer.h.8.ln_2": 0.736,
      "transformer.h.8.mlp": 0.744,
      "transformer.h.9.ln_1": 0.708,
      "transformer.h.9.attn": 0.704,
      "transformer.h.9.ln_2": 0.764,
      "transformer.h.9.mlp": 0.748,
      "transformer.h.10.ln_1": 0.736,
      "transformer.h.10.attn": 0.74,
      "transformer.h.10.ln_2": 0.76,
      "transformer.h.10.mlp": 0.748,
      "transformer.h.11.ln_1": 0.744,
      "transformer.h.11.attn": 0.696,
      "transformer.h.11.ln_2": 0.78,
      "transformer.h.11.mlp": 0.688
    },
    "training_scores": {},
    "test_scores": {}
  },
  "parameters": {
    "aperture": [
      0.01
    ],
    "n_examples": [
      250
    ]
  }
}