{
  "model": {
    "name": "EleutherAI-gpt-neo-125M",
    "dataset_seed": 42
  },
  "experiment": {
    "type": "conceptor_layers",
    "module": "transformer.h.11.mlp"
  },
  "metrics": {
    "validation_scores": {
      "transformer.h.2.ln_1": 0.655310621242485,
      "transformer.h.2.attn": 0.632,
      "transformer.h.2.ln_2": 0.664,
      "transformer.h.2.mlp": 0.69,
      "transformer.h.4.ln_1": 0.666,
      "transformer.h.4.attn": 0.664,
      "transformer.h.4.ln_2": 0.676,
      "transformer.h.4.mlp": 0.71,
      "transformer.h.6.ln_1": 0.694,
      "transformer.h.6.attn": 0.67,
      "transformer.h.6.ln_2": 0.716,
      "transformer.h.6.mlp": 0.698,
      "transformer.h.8.ln_1": 0.706,
      "transformer.h.8.attn": 0.692,
      "transformer.h.8.ln_2": 0.744,
      "transformer.h.8.mlp": 0.73,
      "transformer.h.9.ln_1": 0.74,
      "transformer.h.9.attn": 0.714,
      "transformer.h.9.ln_2": 0.758,
      "transformer.h.9.mlp": 0.748,
      "transformer.h.10.ln_1": 0.754,
      "transformer.h.10.attn": 0.754,
      "transformer.h.10.ln_2": 0.758,
      "transformer.h.10.mlp": 0.766,
      "transformer.h.11.ln_1": 0.762,
      "transformer.h.11.attn": 0.698,
      "transformer.h.11.ln_2": 0.77,
      "transformer.h.11.mlp": 0.676
    },
    "training_scores": {},
    "test_scores": {}
  },
  "parameters": {
    "aperture": [
      0.01
    ],
    "n_examples": [
      3000
    ]
  }
}