{
  "model": {
    "name": "EleutherAI-gpt-neo-125M",
    "dataset_seed": 7
  },
  "experiment": {
    "type": "conceptor_layers",
    "module": "transformer.h.11.mlp"
  },
  "metrics": {
    "validation_scores": {
      "transformer.h.2.ln_1": 0.618,
      "transformer.h.2.attn": 0.618,
      "transformer.h.2.ln_2": 0.632,
      "transformer.h.2.mlp": 0.676,
      "transformer.h.4.ln_1": 0.64,
      "transformer.h.4.attn": 0.65,
      "transformer.h.4.ln_2": 0.6452905811623246,
      "transformer.h.4.mlp": 0.706,
      "transformer.h.6.ln_1": 0.6492985971943888,
      "transformer.h.6.attn": 0.658,
      "transformer.h.6.ln_2": 0.69,
      "transformer.h.6.mlp": 0.682,
      "transformer.h.8.ln_1": 0.676,
      "transformer.h.8.attn": 0.684,
      "transformer.h.8.ln_2": 0.73,
      "transformer.h.8.mlp": 0.71,
      "transformer.h.9.ln_1": 0.714,
      "transformer.h.9.attn": 0.696,
      "transformer.h.9.ln_2": 0.742,
      "transformer.h.9.mlp": 0.732,
      "transformer.h.10.ln_1": 0.72,
      "transformer.h.10.attn": 0.728,
      "transformer.h.10.ln_2": 0.754,
      "transformer.h.10.mlp": 0.74,
      "transformer.h.11.ln_1": 0.746,
      "transformer.h.11.attn": 0.706,
      "transformer.h.11.ln_2": 0.772,
      "transformer.h.11.mlp": 0.678
    },
    "training_scores": {},
    "test_scores": {}
  },
  "parameters": {
    "aperture": [
      0.01
    ],
    "n_examples": [
      3000
    ]
  }
}