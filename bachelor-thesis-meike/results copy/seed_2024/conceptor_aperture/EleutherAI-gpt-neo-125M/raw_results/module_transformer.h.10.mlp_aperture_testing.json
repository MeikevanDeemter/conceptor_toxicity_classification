{
  "model": {
    "name": "EleutherAI-gpt-neo-125M",
    "dataset_seed": 2024
  },
  "experiment": {
    "type": "conceptor_aperture",
    "module": "transformer.h.10.mlp"
  },
  "metrics": {
    "validation_scores": {
      "1e-05": 0.768,
      "5e-05": 0.768,
      "0.0001": 0.768,
      "0.0005": 0.768,
      "0.001": 0.768,
      "0.005": 0.768,
      "0.01": 0.768,
      "0.05": 0.768,
      "0.1": 0.768,
      "0.5": 0.768,
      "1.0": 0.772,
      "5.0": 0.778,
      "10.0": 0.782,
      "50.0": 0.764,
      "100.0": 0.744,
      "500.0": 0.7244258872651357,
      "1000.0": 0.6170798898071626,
      "5000.0": 0.504885993485342,
      "10000.0": 0.5460992907801419
    },
    "training_scores": {},
    "test_scores": {}
  },
  "parameters": {
    "n_examples": [
      5,
      10,
      20,
      30,
      40,
      50,
      100,
      150,
      200,
      250,
      300,
      350,
      400,
      450,
      500,
      550,
      600,
      650,
      700,
      750,
      800,
      850,
      900,
      950,
      1000,
      1050,
      1100,
      1150,
      1200,
      1250,
      1300,
      1350,
      1400,
      1450,
      1500,
      1550,
      1600,
      1650,
      1700,
      1750,
      1800,
      1850,
      1900,
      1950,
      2000,
      2050,
      2100,
      2150,
      2200,
      2250,
      2300,
      2350,
      2400,
      2450,
      2500,
      2550,
      2600,
      2650,
      2700,
      2750,
      2800,
      2850,
      2900,
      2950,
      3000
    ],
    "module_name": "transformer.h.10.mlp"
  }
}